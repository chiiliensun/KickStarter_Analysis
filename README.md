# KickStarter_Analysis
 3 Major Conclusions
 
 
-When looking at the data provided, and using the calculated percentage of successful, live, failed versus canceled, the analysis can conclude that certain categories had higher success rates versus failure rates. The most compelling understanding of this data is by category, Journalism has the highest percentage (100%) to be canceled. Along with understanding there were no Journalism kicker-starters that were successful. The category of Music can be predicted to have the most success due to the retrospective look of 77% that were successful. Essentially this retrospect of this data set could assist potential kick-starter projects to predict if they would be successful in their venture. Failure percentage of each category is relatively high in comparison of successful for most categories with the exception of Music. The highest failure rate can be seen through the category of Food, 70%. With this data set it could be said that potential entrepreneurs can use this to evaluate their chances of success versus failure by category. Or use the failure rates for each category to decide on whether using this type of platform to start one’s business is beneficial for their circumstances. 

-This data set can also look at duration aspect of these past projects or whether the time of each year that projects were started, could help determine the success, failure or cancelation rates. The most interesting understanding of this can be seen when comparing how these projects fare over a year’s time in the chart below.The cancelation of the projects are relatively comparable for the entire year but the interesting data can be seen by just looking at the success throughout the year. There is a dramatic spike in May when compared to December. Which can conclude that more people are willing to contribute to their projects when not competing with the holiday season and present shopping. Essentially this can assist entrepreneurs, again, to decide when they would want to launch their projects through this platform that would increase their probability of success. 

-After using the major categories and understanding which types of projects are more likely to fail versus obtain success, and using the timeframe analysis to understand when projects have a higher success rate, one can look at further sub-categories. 
The most successful sub-category can be seen by this graph and over 40 sub-categories: Plays were exponentially more successful. The following sub-categories also were 100% successful; classical music, documentary, electronic music, hardware, metal, nonfiction, pop, radio & podcasts, rock, shorts, small batch, tabletop games, and television. Where the following sub-categories were found to be 100% failed; web, video games, restaurants, places, people, nature, mobile games, jazz, gadgets, fiction, faith, drama, children’s books and animation. 

Limitations

 Each conclusion has a relative limitations identified. In the first conclusion, the main categories were compared to another by percentage rates. What wasn’t stated or taken into account is the comparable numbers for each parent category. There were a grand total of 4114 campaigns in this data set. The parent categories were vastly different in the grand total for each. Film & video had 520 campaigns, Food had 200 campaigns, Games had 220 campaigns, Journalism had 24 campaigns, Music had 700 campaigns, Photography had 220 campaigns, Publishing had 237 campaigns, Technology had 600 campaigns, and Theater had 1393 campaigns. These totals also did not account for the current and live campaigns, though these numbers were small enough to discount on the main conclusions. When looking at the difference in total campaigns, the totals were different to note this limitation. For example Journalism only had 24 campaigns attempted and all were canceled. Where Theater had more canceled campaigns, 37, but out of 1393 campaigns. These totals discrepancy is difficult to make any accurate predictions. 

The second limitation is the fact there were four different Outcome categories; canceled, failed, successful and live. The live campaigns again were minimal enough to be ignored on the surface. The cancellation category of outcome is unclear as to what the reason behind the cause is attributed to. What would be the understanding that can be concluded for cancellation rates versus failure rates without the information on why the cancellation occurred? Was it due to the campaign cancelling the kick-starter because they decided that there was not enough backers in the campaign duration? Was it due to technical challenges? There are many questions that can be asked on why there are both cancellation and failed categories and one would want to understand the nuances or possible causes for a campaign to choose to cancel rather than fail. 

Another limitation is the data set is not large enough in each category or sub-category to fully be analyzed in comparison. As stated above, Journalism only had 24 campaigns started. In comparison of Theater had over 1300 campaigns started. This is a large difference which makes analysis difficult to make concrete or subjective conclusions. 

Possible Further Analysis?

What was not mentioned in the prior conclusions nor the limitations, is that this data set encompasses various different countries AND different currencies. It would be interesting and possible to make comparison by Country and/or by currency. This comparison can also be drilled down to different states for U.S.A. and make comparisons by region, state or city. State and City would have to further obtain where these campaigns started in the U.S. 

Another possible analysis could further investigate what the cancellation causes were or understanding why campaigns chose to cancel versus fail. The opposite, successful campaigns, analysis can be investigate as well. The campaign itself to raise the funds for these projects were successful, but how many of these projects were successful outside and beyond this duration of raising funds? Were the Technology 209 successful campaigns successful in putting their product on the market for consumer use? 

The last interesting possible analysis would be further investigation on how each successful versus failed campaigns advertised their projects. Which can be correlated with the below BONUS Analysis. Looking at the difference in backers for each category of failed and successful, the difference is stark and could possibly be beneficial to understand how each of these campaigns advertised. Did the successful campaigns have more advertisement in media, their community, how wealthy was the community they advertised to, and the questions go on. For example, in the parent category of Music, did these campaigns target their own fellow musicians? Did the kick-starter campaigns have assistance from within their own industry and fund raising done within a wealthier group? Or possibly a more wealthy musician backer use their own platform to advertise for a much smaller kick-starter music campaign? 

BONUS Analysis

The variability between successful and failed campaigns on mean or median backers shows the stark contrast. When looking at the raw data of backers for successful campaigns, the variability is much higher within this category. For example, one successful campaign had 2436 backers but another successful campaign had only 50 backers. So this type of data set can be useful but it also does not account for how much each backer contributed versus how much the goal was set at. Including this type of data could make the median or mean backers more sense. 
